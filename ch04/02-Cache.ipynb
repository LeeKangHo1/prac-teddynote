{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐싱(Caching)\n",
    "\n",
    "LangChain은 LLM을 위한 선택적 캐싱 레이어를 제공합니다.\n",
    "\n",
    "이는 두 가지 이유로 유용합니다.\n",
    "\n",
    "- 동일한 완료를 여러 번 요청하는 경우 LLM 공급자에 대한 **API 호출 횟수를 줄여 비용을 절감**할 수 있습니다.\n",
    "- LLM 제공업체에 대한 **API 호출 횟수를 줄여 애플리케이션의 속도를 높일 수** 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH04-Models\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH04-Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 프롬프트를 생성합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{country} 에 대해서 200자 내외로 요약해줘\")\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은 동아시아에 위치한 한반도의 국가로, 북한과 남한으로 나뉘어 있습니다. 서울은 남한의 수도이며, 경제, 문화, 기술에서 세계적인 영향력을 미칩니다. 한국은 역사적으로 고대 왕국에서 시작해 다양한 문화와 전통을 발전시켜왔습니다. 한국 음식, K-POP, 드라마 등은 글로벌한 인기를 끌고 있으며, 정보통신 기술과 제조업에서 강력한 경쟁력을 보이고 있습니다.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InMemoryCache\n",
    "\n",
    "인메모리 캐시를 사용하여 동일 질문에 대한 답변을 저장하고, 캐시에 저장된 답변을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은 동아시아에 위치한 반도 국가로, 한반도와 그 주변의 섬들로 구성되어 있습니다. 서울이 수도이며, 인구는 약 5천만 명입니다. 풍부한 역사와 문화, K-팝과 한국 드라마로 세계적으로 알려져 있습니다. 경제는 첨단 기술과 제조업 중심이며, 교육 수준이 높습니다. 김치와 비빔밥 등 다양한 전통 음식이 있으며, 독특한 언어와 문자(한글)를 가지고 있습니다.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# 인메모리 캐시를 사용합니다.\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은 동아시아에 위치한 반도 국가로, 한반도와 그 주변의 섬들로 구성되어 있습니다. 서울이 수도이며, 인구는 약 5천만 명입니다. 풍부한 역사와 문화, K-팝과 한국 드라마로 세계적으로 알려져 있습니다. 경제는 첨단 기술과 제조업 중심이며, 교육 수준이 높습니다. 김치와 비빔밥 등 다양한 전통 음식이 있으며, 독특한 언어와 문자(한글)를 가지고 있습니다.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 첫 번째 실행 ===\n",
      "응답: 한국의 수도는 서울입니다.\n",
      "\n",
      "=== 두 번째 실행 ===\n",
      "응답: 한국의 수도는 서울입니다.\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 캐시 설정\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# 체인 구성\n",
    "prompt = ChatPromptTemplate.from_template(\"한국의 수도는 무엇인가요?\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"=== 첫 번째 실행 ===\")\n",
    "response1 = chain.invoke({})\n",
    "print(f\"응답: {response1}\")\n",
    "\n",
    "print(\"\\n=== 두 번째 실행 ===\")\n",
    "response2 = chain.invoke({})\n",
    "print(f\"응답: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite Cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import os\n",
    "\n",
    "# 캐시 디렉토리를 생성합니다.\n",
    "if not os.path.exists(\"cache\"):\n",
    "    os.makedirs(\"cache\")\n",
    "\n",
    "# SQLiteCache를 사용합니다.\n",
    "set_llm_cache(SQLiteCache(database_path=\"cache/llm_cache.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
